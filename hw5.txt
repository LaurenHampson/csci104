
Problem 1c: Break QuickSort


Array of 10 doubles that will always have a pivot that is the 2nd largest or 2nd smallest element of the array
	Base cases: Array Length 1--> return, array length 2-> quicksort on the two elements, using the start element to be both the first element and middle element to calculate the median


	1.0 8.0 7.0 10.0 2.0 4.0 5.0 6.0 9.0 3.0

		Start element= 1.0, middle = 2.0, end = 3.0

		the median of these three elements is 2.0, which is the second smallest element of this array

	Sorting the first time:

		1.0 [2.0] 8.0 7.0 10.0 4.0 5.0 6.0 9.0 3.0


			1.0 already sorted because single element base case

			Sorting subarray:8.0 7.0 10.0 4.0 5.0 6.0 9.0 3.0
				Start = 8.0 Middle = 4.0 End = 3.0
					Median of these three elements is 4.0 and 4.0 is also the second smallest element in the subarray

				UPDATED FINAL ARRAY: [1.0] [2.0] 3.0 [4.0] 8.0 7.0 10.0 5.0 6.0 9.0


				Sorting Subarray: 8.0 7.0 10.0 5.0 6.0 9.0
					Start = 8.0 Middle = 10.0 End = 9.0

					Median of these tree elements is 9.0 which is also the second largest element in the subarray

					UPDATED FINAL ARRAY: [1.0][2.0][3.0][4.0] 8.0 7.0 5.0 6.0 [9.0] 10.0


					Sorting Subarray: 8.0 7.0 5.0 6.0

						Start = 8.0, Middle = 7.0, end = 6.0

							Median of these three elements is 7.0 which is also the second largest element in the subarray

								UPDATED FINAL ARRAY: [1.0][2.0][3.0][4.0] 5.0 6.0 [7.0] 8.0 [9.0] [10.0]

						Sorting Subarray: 5.0 6.0

							Start= 5.0, "Middle" = 5.0; End = 6.0

							If you automatically use start as one of your base cases, the final array will be




			[1.0][2.0][3.0][4.0] [5.0] [6.0] [7.0] [8.0] [9.0] [10.0]






Problem 2: Break Interpolation Search

	One example of an array of size n of double that would cause interpolation Search tow queryeach entry of the arry before finally finding its target is:

		1.0, 2.0, 3.0, ..., 999.0, 1000.0, 100000000.0

		This is an array of size 1001.

		Although this is for the most part a uniformally distributed array, it will still
		end up taking O(N) to search for the correct value in this array.

		For example if you want to use interpolation search to search for 1000.0
		in this array, it will take 1000 queries.

		Due to the fact that the numerical value of the final key increases exponentially,
		it acts as an outlier, which will cause the search to always start at the beginning of
		the range.

		This is because it makes the number resulting from (index range/value range) to be very 
		small, skewing the overall calculation of the target index, that one would expect in 
		a uniformally distributed array.


Problem 3: Meidan Finding in Linear Time


	Part a(set up a Reccurence relation)
			1.Analyze the running time of all the parts of the function other than the recursive calls. You may use everything you know about the running time of linear search, the partition function, and Insertion Sort.

			T quantile (T* a, int left, int right, int k)
			{ 

				*****The if statement below will run in constant time
						Although insertion sorts runtime is technically O(n)
						this InsertionSort will run in constant time because 
						the size of the array passed into it every time will most
						likely be a chunk of 5 numbers.  Because this number is the
						same and relatively small, this instance of insertinos sort can 
						be simplified down to O(1).  IF the size of the array was unknown
						it would still be less than or equal to 10, which is still a relatively
						small constant

				if (right <= left + 10) 
				  {  
				    InsertionSort (a, left, right); 
				    return a[k+left];
				  }


				else
				{
					int smallsize = (right-left)/5;
					T *b = new T[smallsize];

					**** This for loop will run in O(n/5) = O(n), because every recursive call that
					     it makes will enter the if statement that runs in O(1), given that
					     the size of the array passed in every time is 5 

					 for (int i = 0; i < smallsize; i ++) 
       					b[i] = quantile (a, left+5*i, left+5*(i+1)-1, 2);


       				**** recursive call, do not analyze
       				T pivot = quantile (b, 0, smallsize-1, smallsize/2);


       				**** Lineear search runs in O(n), analysis done in class
       				int p = linearSearch (a, left, right, pivot);

       				**** Swap done in O(1), no effect on overall reccurrence
				    a.swap (p, right);

				    **** As analyzed in class, partition runs in Theta(n)
				    	we learned that it does this because it runs one linear scan through the array, plus some constant time 
				    int m = partition (a, left, right);

				    ***Runs in O(1), no effect on overall run time
				    if (left+k == m) return a[m];

				    ***The last to lines are both recursive calls which I am not analyzing yet

				    else if (left+k < m) return quantile (a, left, m-1, k);
				    else return quantile (a, m+1, right, k-(m+1-left));


				 }

				}


		2. In the loop that assigns values to each b[i], how big is the input size for each recursive call? 
		Thus, how long do the recursive calls to quantile() take? How many such recursive calls are made? 
		How far can you simplify the total time for all of this?

			The input size for each recursive call is 5. After dividing the array by 5, it then passes in 5 
			numbers of the array at a time, in order to find the median of those numbers.


			The recursive call to quantile() will only take O(1), this is because 5 is a small enough 
			constant that insertion sort will run in constant time, as each input passed to it will be of 
			size 5. Although it is technically O(n), this small of a number will simplify the running time 
			down to O(1) given that it has little overhead.

			N/5 recursive calls are made.  Although N could change, given that it is the smallsize which is 
			the right index minus the left index, it will always be the size of the current array or 
			subarray divided by 5.

			The total run time for all of this can be simplified down to O(n), because the for loop takes    
			O(n) to loop through the current array, and the recursize calls to quantile each take O(1), 
			given the small size of the chunk of the array passed in.


		3. In the recursive call that assigns a value to pivot, how big is the array? Thus, how long does 
		the recursive call take?

			In the recursive call that assigns a value to pivot, the array will be size n/5, this is because 
			smallsize is passed in, and smallsize is the size of the array of the medians of the original 
			array or subarray, so it will be size of full array divided by five

			That recursive call will run in a time of O(n/5) or O(n) as well because the runtime of the rest 
			of the function before it runs in O(n), and it is a single recursive call.



		4.Explain why at least 3n/10 elements in a are <= the pivot, and at least 3n/10 elements are >= the 
		pivot. Which are those elements? (You can ignore constant terms, i.e., if it's really 3n/10-4 
		elements which are smaller/larger, feel free to discard the -4 term.)

			Because the call to insertion sort finds the medians of the medians of size 5 subarrays, on 
			uniformally partitioned n/5 chunks of an array, the chosen pivot will end up being less than and 
			greater than half of the medians in the medians of medians array of size n/5.  This will end up 
			being about n/10 elements.

			Because each of the medians is a median of five, it makes it (n/10*the number of chunks of 5 
			above it) less than the other elemens and (n/10*the number of chunks of 5 below it) greater than 
			the other elements given. Because this number is a median of a medians, the medians of the 
			chunks below and above it will have two other numbers before and after the median that are less 
			than or greater than the median of the medians

			IF there is at least one chunk below the median, there will be two numbers in that chunk that 
			are less than its own median, which is 2n/10 elements that are less than the median of the 
			median.  Because the median of the chunk below the chunk of the array, is less than the median 
			of the median, and there are two elements in the smaller chunk that are less than the median of 
			the medians, there will be a total of at least 3n/10 elements that are less than or equal to the 
			pivot. 

			This can also be applied to the one chunk at least who's median is greater than the median of 
			the medians. 


		5. As a result of your analysis, how big at most is the array for the recursive call that is made in 
		the last or second-to-last line?

			Because at least 3n/10 of the elements in the array are above or below the pivot, the size of 
			the array in the recursive call that is made in the last line or second-to-last line will be at 
			most 7n/10 of the elements left in the array. 

		6. Putting everything together, show that the recurrence relation for the running time of the 
		quantile() function is T(n) = T(n/5)+T(7n/10)+Θ(n) n >= 10. Also specify the base case for your 
		recurrence relation.

			In the reccurrence relation:

				T(n/5) refers to the call to quantile that is done on the "smallsize" array
					This is the median of the medians and will always be the current size of the array
					divided by 5.

				T(7n/10) refers to the max size of the array in the recursive calls in the last two lines,
				given that at least 3n/10 elements in the array are greater than or less than the pivot 
				point obtained from finding the medians of the medians of the original array

				Θ(n)--> This is the runtime given for the partition function because it uses linear search 
				once plus some constant time

				The base case of the recurrence relation is when the size of the array is less than 10, 
				given that it will enter the if statement that calls insertion sort when a recursive call is 
				made, and it returns an element


	Part b(solve the Reccurence)

		I wrote out this part of the problem on paper, and have uploaded it in the document hw5.pdf

		look there for the answer